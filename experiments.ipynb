{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from loading import load_data, load_test\n",
    "from preprocessing import preprocess_x, preprocess_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x_orig, data_y_orig = load_data() # loads from \".\\data\" by default\n",
    "test_x_orig = load_test() # this is for submission purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "OMR                0.818498\n",
       "min_dt_TV1_TV3     0.313622\n",
       "mean_dt_TV1_TV3    0.313622\n",
       "med_dt_TV1_TV3     0.313622\n",
       "min_dt_TV1_TV2     0.312334\n",
       "mean_dt_TV1_TV2    0.312334\n",
       "med_dt_TV1_TV2     0.312334\n",
       "min_dt_TV1_TV4     0.311878\n",
       "mean_dt_TV1_TV4    0.311878\n",
       "med_dt_TV1_TV4     0.311878\n",
       "min_dt_TV1         0.041705\n",
       "mean_dt_TV1        0.041705\n",
       "med_dt_TV1         0.041705\n",
       "OTR                0.016167\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "# look at NaN data\n",
    "s = data_x_orig.isna().sum()/data_x_orig.count()\n",
    "s[data_x_orig.isna().any()].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = preprocess_x(data_x_orig)\n",
    "data_y = preprocess_y(data_x_orig, data_y_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# give ids to traders\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "trader_encoder = LabelEncoder()\n",
    "groups = trader_encoder.fit_transform(data_x_orig[\"Trader\"].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# send everything to numpy arrays\n",
    "X = data_x.to_numpy()\n",
    "y = data_y.to_numpy()"
   ]
  },
  {
   "source": [
    "## Model Selection"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# build a list of dicts that says which classifier heads to test, and what params to test on them\n",
    "search_params = [\n",
    "    # # already tested, worse than SGDClassifier(class_weight='balanced', loss='log'):\n",
    "    # {\n",
    "    #     \"clf\": [KNeighborsClassifier()], \n",
    "    #     \"clf__n_neighbors\": np.arange(3,16),\n",
    "    #     \"clf__weights\": ['uniform', 'distance']\n",
    "    # },\n",
    "    # {\n",
    "    #     \"clf\": [ExtraTreesClassifier(max_features=\"sqrt\")],\n",
    "    #     \"clf__n_estimators\": np.linspace(50,200, num=50, dtype = int)\n",
    "    # },\n",
    "    # {\n",
    "    #     \"clf\": [SGDClassifier()],\n",
    "    #     \"clf__class_weight\": [None, \"balanced\"],\n",
    "    #     \"clf__loss\": ['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron','squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive']\n",
    "    # },\n",
    "    {\n",
    "        \"clf\": [GradientBoostingClassifier(max_features='sqrt')],\n",
    "        \"clf__loss\": ['deviance', 'exponential'],\n",
    "        \"clf__learning_rate\": np.logspace(-3,0, num = 15),\n",
    "    },\n",
    "    {\n",
    "        \"clf\": [SGDClassifier(class_weight='balanced', loss='log')]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupKFold, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# these estimators will be appled sequentially to the data:\n",
    "pipe = Pipeline([\n",
    "    (\"standardisation\", StandardScaler()),\n",
    "    # (\"reduce_dim\", PCA(n_components='mle')), # unnecessary, MLE only removes the last dimension \n",
    "    (\"clf\", SGDClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 8 folds for each of 31 candidates, totalling 248 fits\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.7317939512566107"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "#split dataset into training and validation by trader\n",
    "gkf = GroupKFold(n_splits=8).split(X, y, groups)\n",
    "\n",
    "search = GridSearchCV(\n",
    "    pipe,\n",
    "    search_params,\n",
    "    #n_iter=100,\n",
    "    cv=gkf,\n",
    "    scoring=\"f1_micro\",\n",
    "    n_jobs=-1,\n",
    "    pre_dispatch=\"2*n_jobs\",\n",
    "    verbose=10\n",
    ")\n",
    "\n",
    "search.fit(X, y)\n",
    "search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'clf': GradientBoostingClassifier(learning_rate=0.22758459260747887,\n",
       "                            max_features='sqrt'),\n",
       " 'clf__learning_rate': 0.22758459260747887,\n",
       " 'clf__loss': 'deviance'}"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "source": [
    "## Postprocessing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = preprocess_x(test_x_orig).to_numpy()\n",
    "y_pred = search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import classes\n",
    "id_to_classes = dict(enumerate(list(classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "traders = test_x_orig[\"Trader\"]\n",
    "results_raw = pd.Series(y_pred, index=test_x_orig[\"Trader\"]).replace(id_to_classes)\n",
    "grouped = results_raw.groupby(\"Trader\")\n",
    "counts = grouped.value_counts().unstack(level=1).fillna(0)\n",
    "ratios = counts.div(counts.sum(axis=\"columns\"), axis = \"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Trader\n",
       "Adelaide            NON HFT\n",
       "Alana               NON HFT\n",
       "Alcmene             NON HFT\n",
       "Alice                   HFT\n",
       "Alices Sister       NON HFT\n",
       "                     ...   \n",
       "Monstro                 MIX\n",
       "Morgana                 MIX\n",
       "The Doorknob        NON HFT\n",
       "The Doorman             HFT\n",
       "The Magic Mirror        MIX\n",
       "Name: type, Length: 85, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "# implement the rule\n",
    "hft_threshold = 0.85\n",
    "mix_threshold = 0.5\n",
    "\n",
    "results = pd.Series([\"NON HFT\" for _ in range(len(counts))], index=counts.index, name =\"type\")\n",
    "results[ratios[\"MIX\"] > mix_threshold] = \"MIX\"\n",
    "results[ratios[\"HFT\"] > hft_threshold] = \"HFT\"\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(\"results.csv\")"
   ]
  },
  {
   "source": [
    "## Additional experiments"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "metadata": {},
     "execution_count": 81
    }
   ],
   "source": [
    "# number of components found by the MLE approach:\n",
    "pca = search.best_estimator_.get_params()[\"reduce_dim\"]\n",
    "pca.n_components_"
   ]
  }
 ]
}